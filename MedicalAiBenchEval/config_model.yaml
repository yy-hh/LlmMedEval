# Medical AI Model Configuration
#
# âš ï¸  IMPORTANT: OpenAI-Compatible API Only
# This system currently supports ONLY OpenAI-compatible API interfaces.
# All models must provide OpenAI-compatible endpoints, regardless of the actual provider.
#
# ğŸ”§ API Configuration Guide
# Step 1: Set environment variables (Linux/Mac):
#   export OPENAI_API_KEY="sk-xxx"
#   export OPENAI_BASE_URL="https://api.openai.com/v1"
# Step 2: Windows PowerShell:
#   $Env:OPENAI_API_KEY="sk-xxx"
#
# ğŸŒ Third-Party Multi-Model Platforms (Recommended):
# These platforms provide OpenAI-compatible APIs for multiple models:
#
# â€¢ OpenRouter (https://openrouter.ai/)
#   - Supports Claude, Gemini, GPT, and many other models via OpenAI-compatible API
#   - Example: export OPENROUTER_API_KEY="sk-or-xxx"
#   - Base URL: https://openrouter.ai/api/v1
#
# â€¢ Together AI (https://together.ai/)
#   - Supports various open-source and commercial models
#   - Example: export TOGETHER_API_KEY="xxx"
#   - Base URL: https://api.together.xyz/v1
#
# â€¢ Anyscale (https://anyscale.com/)
#   - Supports multiple LLMs via OpenAI-compatible endpoints
#   - Example: export ANYSCALE_API_KEY="xxx"
#   - Base URL: https://api.endpoints.anyscale.com/v1
#
# ğŸ“‹ Supported Providers (OpenAI-Compatible Only):
#â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
#â”‚ Provider â”‚ api_key_env         â”‚ api_base_env         â”‚ Example Model        â”‚ Status â”‚
#â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
#â”‚ OpenAI   â”‚ OPENAI_API_KEY      â”‚ OPENAI_BASE_URL      â”‚ gpt-4-turbo          â”‚ âœ… Native â”‚
#â”‚ OpenRouterâ”‚ OPENROUTER_API_KEY  â”‚ OPENROUTER_BASE_URL  â”‚ anthropic/claude-3.5 â”‚ âœ… Multi-Model â”‚
#â”‚ Together â”‚ TOGETHER_API_KEY    â”‚ TOGETHER_BASE_URL    â”‚ meta-llama/llama-3   â”‚ âœ… Multi-Model â”‚
#â”‚ Anyscale â”‚ ANYSCALE_API_KEY    â”‚ ANYSCALE_BASE_URL    â”‚ mistralai/mixtral    â”‚ âœ… Multi-Model â”‚
#â”‚ Kimi     â”‚ MOONSHOT_API_KEY    â”‚ MOONSHOT_BASE_URL    â”‚ kimi-latest          â”‚ âœ… Compatible â”‚
#â”‚ Qwen     â”‚ DASHSCOPE_API_KEY   â”‚ DASHSCOPE_BASE_URL   â”‚ qwen-max             â”‚ âœ… Compatible â”‚
#â”‚ DeepSeek â”‚ DEEPSEEK_API_KEY    â”‚ DEEPSEEK_BASE_URL    â”‚ deepseek-chat        â”‚ âœ… Compatible â”‚
#â”‚ Baichuan â”‚ BAICHUAN_API_KEY    â”‚ BAICHUAN_BASE_URL    â”‚ baichuan-53b         â”‚ âœ… Compatible â”‚
#â”‚ Zhipu    â”‚ ZHIPU_API_KEY       â”‚ ZHIPU_BASE_URL       â”‚ chatglm-4            â”‚ âœ… Compatible â”‚
#â”‚ Claude   â”‚ ANTHROPIC_API_KEY   â”‚ ANTHROPIC_BASE_URL   â”‚ claude-3.5           â”‚ âŒ Not Supported â”‚
#â”‚ Gemini   â”‚ GOOGLE_API_KEY      â”‚ GOOGLE_BASE_URL      â”‚ gemini-1.5           â”‚ âŒ Not Supported â”‚
#â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
#
# âš ï¸  Technical Implementation Note:
# - The system uses LangChain's ChatOpenAI client for ALL models
# - All API calls are made through OpenAI-compatible interfaces
# - Native APIs (like Anthropic's Claude API or Google's Gemini API) are NOT supported
# - Providers must offer OpenAI-compatible endpoints to work with this system
# - Third-party platforms like OpenRouter enable access to models that don't natively support OpenAI API
#
# ğŸ¯ Medical Model Recommendations (OpenAI-Compatible):
# â€¢ Diagnostic tasks: gpt-4-turbo, deepseek-chat (high accuracy)
# â€¢ Chinese medical: qwen-max, baichuan-medical (better CJK support)
# â€¢ Cost-effective: deepseek-chat, kimi (good balance)
# â€¢ Multi-model access: OpenRouter (Claude, Gemini via compatible API)
# â€¢ Local deployment: local-llama3-medical (privacy-focused, via OpenAI-compatible server)
#
# ğŸ’¡ Example Configurations:
#
# # OpenRouter - Access Claude via OpenAI-compatible API
# claude_via_openrouter:
#   api_key_env: "OPENROUTER_API_KEY"
#   api_base_env: "OPENROUTER_BASE_URL"  # https://openrouter.ai/api/v1
#   model: "anthropic/claude-3-5-sonnet-20241022"
#   temperature: 0.2
#   max_tokens: 4000
#
# # OpenRouter - Access Gemini via OpenAI-compatible API
# gemini_via_openrouter:
#   api_key_env: "OPENROUTER_API_KEY"
#   api_base_env: "OPENROUTER_BASE_URL"  # https://openrouter.ai/api/v1
#   model: "google/gemini-pro-1.5"
#   temperature: 0.1
#   max_tokens: 4000
#
models:
  m1:
    api_key_env: "ANT_API_KEY"
    api_base_env: "ANT_BASE_URL"
    model: "Kimi-K2-Instruct"
    temperature: 0
    max_tokens: 32678
    extra_body:
      enable_sec_check: false

  m2:
    api_key_env: "ANTCHAT_API_KEY"
    api_base_env: "ANTCHAT_BASE_URL"
    model: "Qwen3-235B-A22B-Instruct-2507"
    temperature: 0
    max_tokens: 32678
    extra_body:
      top_k: 20
      min_p: 0
      enable_sec_check: false

  # m3:
  #   api_key_env: "ANTCHAT_API_KEY"
  #   api_base_env: "ANTCHAT_BASE_URL"
  #   model: "DeepSeek-V3.1"
  #   temperature: 0
  #   max_tokens: 32678


  m3:
    api_key_env: "OPENAI_API_KEY"
    api_base_env: "OPENAI_BASE_URL"
    model: "gpt-5.2"
    temperature: 1



  m4:
    api_key_env: "OPENAI_API_KEY"
    api_base_env: "OPENAI_BASE_URL"
    model: "gpt-4.1"
    temperature: 1
    #max_tokens: 32678

  m5:
    api_key_env: "MATRIX_API_KEY_V2"
    api_base_env: "MATRIX_BASE_URL"
    model: "gemini-2.5-pro"
    reasoning_effort: "high"
    max_tokens: 32678
    temperature: 0.7

  # Example: Claude via OpenRouter (commented out - uncomment to use)
  # m6:
  #   api_key_env: "OPENROUTER_API_KEY"
  #   api_base_env: "OPENROUTER_BASE_URL"
  #   model: "anthropic/claude-3-5-sonnet-20241022"
  #   temperature: 0.2
  #   max_tokens: 4000

  # Example: Gemini via OpenRouter (commented out - uncomment to use)
  # m7:
  #   api_key_env: "OPENROUTER_API_KEY"
  #   api_base_env: "OPENROUTER_BASE_URL"
  #   model: "google/gemini-pro-1.5"
  #   temperature: 0.1
  #   max_tokens: 4000